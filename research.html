<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
<meta name="description" content="description"/>
<meta name="keywords" content="keywords"/> 
<meta name="author" content="author"/> 
<link rel="stylesheet" type="text/css" href="default.css" media="screen"/>
<title>Nick Wang at NCTU</title>
</head>

<body>

<div class="outer-container">

<div class="inner-container">

	<div class="header">
		
		<div class="title">
			<span class="sitename"><a href="index.html">Assistive Robotics Group</a>&nbsp;&nbsp;&nbsp;<a href="index_ch.html">機器人與輔助科技實驗室</a></span>
		</div>

	</div>

	<div class="path">

		<a href="index.html">Home</a> 
		<a href="people.html">People</a> 
		<a href="research.html">Research</a> 
		<a href="publications.html">Publications</a>
		<a href="courses.html">Courses</a>
	</div>

	<div class="main">
		<h0>Robotics, Vision, and Assistive Technology</h0>
		<p></p>
		<div class="fullcontent">
			<div class="teaser">
				<img src="research/bocelli-project-teaser.gif" width="210" height="100" border="0">
			</div>
			<div class="proj">
				<h1>Wearable Navigation System for the Blind and Visually Impaired</h1>
				<p>
					Our team develops wearable, miniaturized, energy-efficient, and soft robotic systems 
					to provide key vision functionalities and navigation feedbacks for blind and visually impaired people. 
					For safe mobility, we develop methods for independent awareness of obstacles, drop-offs, ascents, descents, 
					and also important objects or landmarks. 
					A haptic array and rapidly refreshable Braille device are used to deliver information about the surroundings. 
					<a href="research/CPS_NickWang_poster_jpg.pdf" target="_blank">Poster</a>
					<a href="http://projects.csail.mit.edu/bocelli/" target="_blank">Website (2014)</a>
				</p>
			</div>
		</div>
		<div class="fullcontent">
			<div class="teaser">
				<img src="research/robotx_placard.gif" height="120" width="200" />
			</div>
			<div class="proj">
				<h1>RobotX Competition</h1>
				<p>
				The inaugural RobotX competition was held in Singapore in Oct. 2014. 
				The purpose of the competition was to challenge teams to develop new strategies for tackling unique and
				important problems in marine robotics. Placard detection is one of the tasks, and our key design objectives were:
				1. Robustness to degradation caused by motion, scale and perspective transformation from different viewing positions, 
				warp and occlusion caused by wind, and variants of color from light condition, 2. Speed and accuracy to support real-time decision-making.
				Ultimately the MIT/Olin team narrowly <strong>won first place</strong> in a competitive field.
				<a href="publications/fsr2015_robotx.pdf" target="_blank">Paper</a>
				<a href="http://newsoffice.mit.edu/2014/csail-meche-marine-experts-win-robotx-self-driving-boat-competition-1030" target="_blank">MIT News</a>
				</p>
			</div>
		<div class="fullcontent">
			<div class="teaser">
				<img src="research/multiple_observation_integration.gif" height="160" width="200" />
			</div>
			<div class="proj">
				<h1>Spatially Prioritized and Persistent Text Detection and Decoding</h1>
				<p>
					Our method uses simultaneous
					localization and mapping (SLAM) to extract planar “tiles” repre-
					senting scene surfaces.
					This paper’s contributions include: 1) spatiotemporal fusion
					of tile observations via SLAM, prior to inspection, thereby
					improving the quality of the input data; and 2) combination of
					multiple noisy text observations into a single higher-confidence
					estimate of environmental text.
					<a href="publications/Wang_cbdar2013.pdf" target="_blank">Paper</a>
				</p>
			</div>
		</div>

		</div>
		<h0>Visual Attention and Scene Perception</h0>
		<p></p>
		<div class="fullcontent">
			<div class="teaser">
				<p></p>
				<img src="research/jov_text_attraction.gif" width="130" height="130" border="0">
			</div>
			<div class="proj">
				<h1>The Attraction of Visual Attention to Texts in Real-World Scenes</h1>
				<h2><em>Where can you more likely find text?</em></h2>
				<p>
					The present study was aimed at investigating its underlying factors of human visual attention attracted by texts. 
					The following main results were obtained: (a) Greater fixation probability and
					shorter minimum fixation distance of texts confirmed the higher attractiveness of texts; (b) the locations where texts are
					typically placed contribute partially to this effect; (c) specific visual features of texts, rather than typically salient features
					(e.g., color, orientation, and contrast), are the main attractors of attention; (d) the meaningfulness of texts does not add to
					their attentional capture; and (e) the attraction of attention depends to some extent on the observer’s familiarity with the
					writing system and language of a given text.
					<a href="publications/WangPomplun2012.pdf" target="_blank"> Paper</a>
				</p>
			</div>
		</div>
		<h0>Cognitive Models and Reading</h0>
		<p></p>
		<div class="fullcontent">
			<div class="teaser">
				<img src="research/brm.gif" width="210" height="200" border="0">
			</div>
			<div class="proj">
				<h1>Predicting Semantic Transparency Judgments</h1>
				<h2><em>Do you read “butter” when you read “butterfly”? Or “馬” for “馬虎”?</em></h2>
					The morphological constituents of English compounds and two-character Chinese compounds may differ in meaning from the whole word.
					The proposed models successfully predicted participants’ transparency ratings, and the prediction is influenced by the differences in raters’ morphological processing 
					in the different writing systems. The dominance of lexical meaning, semantic transparency, and the average similarity between all pairs within a morphological family 
					are provided, and practical applications for future studies are discussed.
					<a href="publications/Wang2014_brm.pdf" target="_blank">Paper</a>
					<a href="http://www.lsa.url.tw/modules/lsa/" target="_blank">Website</a>			
			</div>		
		</div>
		<div class="fullcontent">
			<div class="teaser">
				<p></p>
				<img src="research/chinese_svd.gif" width="210" height="160" border="0">
				<br><br><br>
			</div>
			<div class="proj">
				<h1>Degraded Character Recognition</h1>
				<h2><em>Can you read these sentence?</em></h2>
				<p>
					It is known that not all letters are of equal importance to the word recognition process, i.e., changing initial or exterior letters are more disruptchanging.
		 			Consistent results have been found for Chinese characters, and first-written strokes are more important for reading.
					This study compares the effects of high-level learnt stroke writting order and low-level features obtained via pixel-level singular value decompostion (SVD) 
					to readers' degraded character recognition. Our results suggest that the most important segments determined by SVD, which has no information about stroke writing order, 						can identify first-written strokes. Furthermore, our results suggest that contour may be correlated with stroke writing order. 
					<a href="publications/Wang2013-jrir.pdf" target="_blank"> Paper</a>
					<a href="publications/CICEM_Talk_NickWang.pdf" target="_blank">Slides</a>
			</div>
		</div>
		<div class="fullcontent">
			<div class="teaser">
			</div>
			<div class="proj">
			</div>	
		</div>
		<div class="fullcontent">
			<div class="teaser">
			</div>
			<div class="proj">
			</div>	
		
		</div>
		<div class="clearer">&nbsp;</div>

	</div>

	<div class="footer">

		<span class="left">
			&copy; H.C. Wang
		</span>

		<span class="right"><a href="http://templates.arcsin.se/">Website template</a> by <a href="http://arcsin.se/">Arcsin</a></span>

		<div class="clearer"></div>

	</div>

</div>

</div>

</body>

</html>
